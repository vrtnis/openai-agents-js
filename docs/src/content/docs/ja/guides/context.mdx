---
title: コンテキスト管理
description: Learn how to provide local data via RunContext and expose context to the LLM
---

import { Aside, Code } from '@astrojs/starlight/components';
import localContextExample from '../../../../../../examples/docs/context/localContext.ts?raw';

コンテキストという言葉には複数の意味があります。ここでは主に 2 つの種類のコンテキストを扱います。

1. **ローカルコンテキスト** — 実行中にコードからアクセスできるもの。ツールが必要とする依存関係やデータ、`onHandoff` のようなコールバック、ライフサイクルフックなど
2. **エージェント／ LLM コンテキスト** — LLM が応答を生成する際に参照できるもの

## ローカルコンテキスト

ローカルコンテキストは `RunContext<T>` 型で表されます。状態や依存関係を保持する任意のオブジェクトを作成し、それを `Runner.run()` に渡します。すべてのツール呼び出しとフックは `RunContext` ラッパーを受け取り、そのオブジェクトを読み書きできます。

<Code
  lang="typescript"
  code={localContextExample}
  title="Local context example"
/>

1 回の実行に参加するすべてのエージェント、ツール、フックは同じ **型** のコンテキストを使う必要があります。

ローカルコンテキストは次のような用途に適しています。

- 実行に関するデータ（ユーザー名、 ID など）
- ロガーやデータフェッチャーなどの依存関係
- ヘルパー関数

<Aside type="note">
  コンテキストオブジェクトは **LLM に送信されません**
  。完全にローカルなものなので自由に読み書きできます。
</Aside>

## エージェント／ LLM コンテキスト

LLM が呼び出されるとき、 LLM が参照できるデータは会話履歴だけです。追加情報を渡すには次の方法があります。

1. エージェントの `instructions` に追加する — システムメッセージや開発者メッセージとも呼ばれます。静的な文字列でも、コンテキストを受け取って文字列を返す関数でも構いません。
2. `Runner.run()` を呼び出す際の `input` に含める。`instructions` を使う方法に似ていますが、メッセージを [指揮系統](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command) 内でより下位に配置できます。
3. 関数ツールを介して公開し、 LLM が必要に応じてデータを取得できるようにする
4. リトリーバルツールや Web 検索ツールを使用し、ファイル・データベース・Web から関連データを取得して回答を裏付ける
